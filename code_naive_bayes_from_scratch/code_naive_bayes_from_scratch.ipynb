{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`63070501061 S.RAKNA`\n",
    "\n",
    "> 4 hr.\n",
    "\n",
    "# Code Naive Bayes from Scratch\n",
    "- Write a program to read the *Iris* dataset, \n",
    "- split into 2 parts: training and testing just like it was done in the example. \n",
    "- Then write your own code to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "the_data = load_iris()  # get the data from sklearn\n",
    "label_name = the_data['target_names']\n",
    "feature_name = the_data['feature_names']\n",
    "labels = the_data['target']\n",
    "features = the_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " the_data data type:  <class 'sklearn.utils._bunch.Bunch'>\n",
      "Feature Names: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "Target Label Names: \n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "features data type:  <class 'numpy.ndarray'>\n",
      "\n",
      "All Features in the data: \n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      "All Labels in the data: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n the_data data type: \", type(the_data))\n",
    "print(\"Feature Names: \\n\", feature_name)\n",
    "print(\"\\nTarget Label Names: \\n\", label_name)\n",
    "print(\"\\nfeatures data type: \", type(features))\n",
    "print(\"\\nAll Features in the data: \\n\", features)\n",
    "print(\"\\nAll Labels in the data: \\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training features: \n",
      " [[6.4 3.1 5.5 1.8]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [4.6 3.2 1.4 0.2]]\n",
      "\n",
      "Training Labels: \n",
      " [2 1 0 2 2 1 0 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1\n",
      " 2 0 0 2 1 0 0 1 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2\n",
      " 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1\n",
      " 1 1 0 0 0 2 1 2 0]\n",
      "\n",
      "Testing Labels: \n",
      " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# split 70:30\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Spliting our dataset into 2 parts for training and testing\n",
    "training_features, testing_features, training_labels, testing_labels = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=0)\n",
    "print(\"\\nTraining features: \\n\", training_features)\n",
    "print(\"\\nTraining Labels: \\n\", training_labels)\n",
    "print(\"\\nTesting Labels: \\n\", testing_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5 pts. \n",
    "\n",
    "#### a\n",
    "\n",
    "- Find the **mean** and **standard deviation** for each of the 4 features of each of the 3 classes from the training data. \n",
    "- $μ_{ik}$ and $σ_{ik}$ for $i = 1..4, k = 1..3$ \n",
    "- You will get pdfs $P(x_i | c_k)$ for each class using the Gaussian distribution equation with $μ_{ik}$ and $σ_{ik}$ for $i = 1..4, k = 1..3$. \n",
    "- This gets you pdfs: $P(x_1, x_2, x_3, x_4 | c_1), P(x_1, x_2, x_3, x_4 | c_2), P(x_1, x_2, x_3, x_4 | c_3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "stds = {}\n",
    "for label in np.unique(training_labels):\n",
    "    means[label] = np.mean(training_features[training_labels == label], axis=0)\n",
    "    stds[label] = np.std(training_features[training_labels == label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  0  Name:  setosa\n",
      "Label:  1  Name:  versicolor\n",
      "Label:  2  Name:  virginica\n",
      "\n",
      "Means: \n",
      " {0: array([5.02051282, 3.4025641 , 1.46153846, 0.24102564]), 1: array([5.88648649, 2.76216216, 4.21621622, 1.32432432]), 2: array([6.63863636, 2.98863636, 5.56590909, 2.03181818])}\n",
      "\n",
      "Stds: \n",
      " {0: array([0.35961481, 0.37654787, 0.14253274, 0.10553393]), 1: array([0.51368418, 0.32244954, 0.47959077, 0.20189026]), 2: array([0.62385018, 0.3283678 , 0.54269663, 0.25385458])}\n"
     ]
    }
   ],
   "source": [
    "# print index of the label and name of the label\n",
    "for i, label in enumerate(label_name):\n",
    "    print(\"Label: \", i, \" Name: \", label)\n",
    "print(\"\\nMeans: \\n\", means)\n",
    "print(\"\\nStds: \\n\", stds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5 pts. \n",
    "\n",
    "#### b\n",
    "\n",
    "Find the $P(c_k)$ by counting the percent frequency of each class in your training data. \n",
    "Now we have $P(c_k | x_1, x_2, x_3, x_4) ∝ P(x_1, x_2, x_3, x_4 | c_k) * P(c_k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prop: \n",
      " {0: 0.325, 1: 0.30833333333333335, 2: 0.36666666666666664}\n"
     ]
    }
   ],
   "source": [
    "# calculate the probability of a label\n",
    "prob = {}\n",
    "for label in np.unique(training_labels):\n",
    "    prob[label] = np.mean(training_labels == label)\n",
    "print(\"\\nProp: \\n\", prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5 pts. \n",
    "\n",
    "#### c\n",
    "\n",
    "Then for each $(x_1, x_2, x_3, x_4)$ in your test data: find the class $k$ of $1, 2, $ or $3$ for which $P(c_k | x_1, x_2, x_3, x_4)$ is maximum, put that $k$ into array `my_predicted_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predicted_labels = []\n",
    "for feature in testing_features:\n",
    "    # calculate the probability of each label\n",
    "    probs = {}\n",
    "    for label in np.unique(training_labels):\n",
    "        probs[label] = np.prod(np.exp(-(feature - means[label])**2 / (\n",
    "            2 * stds[label]**2)) / (np.sqrt(2 * np.pi) * stds[label])) * prob[label]\n",
    "\n",
    "    # get the label with the highest probability\n",
    "    my_predicted_labels.append(max(probs, key=probs.get)) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My Predicted Labels: \n",
      " [2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMy Predicted Labels: \\n\", my_predicted_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5 pts. \n",
    "\n",
    "#### d\n",
    "\n",
    "Calculate and print the accuracy score from your implementation of Naive Bayes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.where(my_predicted_labels == testing_labels,\n",
    "                    1, 0).sum() / len(testing_labels)\n",
    "print(\"\\nAccuracy: \", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "333d2c9757a75282c9d4867cccb346dd97fbdd6438562bec117fa31e687fe23c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
